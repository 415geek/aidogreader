# -*- coding: utf-8 -*-
# Dog Behavior & Affect Analyzer â€” Cloud-safe, with Simple/Pro sidebar
# - OpenCV å®‰å…¨å¯¼å…¥ï¼›ultralytics YOLOv8n æ¨ç†
# - sklearn / éŸ³é¢‘ ä¸ºå¯é€‰ï¼ˆæœªå®‰è£…æ—¶è‡ªåŠ¨é™çº§åˆ°è§„åˆ™æ¨æ–­ï¼Œæ— æŠ¥é”™ï¼‰
# - ç®€æ´æ¨¡å¼ï¼šåœºæ™¯é¢„è®¾ + â€œé€Ÿåº¦â†”å‡†ç¡®åº¦â€ä¸€é”®æ˜ å°„ï¼›é«˜çº§æ¨¡å¼ï¼šåŸå§‹å‚æ•°å…¨å¼€æ”¾
# - ä¸»åŠ¨å­¦ä¹ ï¼šä½ç½®ä¿¡åº¦ç‰‡æ®µäººå·¥çº æ­£â†’ä¿å­˜æ ·æœ¬â†’ä¾§æ ä¸€é”®è®­ç»ƒï¼ˆè‹¥ sklearn å¯ç”¨ï¼‰

import os, json, time, uuid, math, tempfile
from dataclasses import dataclass
from typing import List, Tuple, Optional

import numpy as np
import streamlit as st

# ---- å®‰å…¨å¯¼å…¥ OpenCVï¼ˆé¿å…ç™½å±ï¼‰----
try:
    import cv2
except Exception as e:
    cv2 = None
    CV2_IMPORT_ERR = e
else:
    CV2_IMPORT_ERR = None

# ---- YOLOï¼ˆUltralyticsï¼‰----
from ultralytics import YOLO

# ---- å¯é€‰ä¾èµ–ï¼šsklearnï¼ˆå¢é‡å­¦ä¹ ï¼‰----
SK_OK = True
try:
    from sklearn.linear_model import SGDClassifier
    from sklearn.preprocessing import StandardScaler
    from sklearn.calibration import CalibratedClassifierCV
except Exception:
    SK_OK = False

import joblib

# ---- å…¨å±€é…ç½® ----
APP_TITLE = "ğŸ¶ Dog Behavior & Affect Analyzer"
DATA_DIR = "data_samples"; MODEL_DIR = "models"; REPORT_DIR = "reports"
os.makedirs(DATA_DIR, exist_ok=True); os.makedirs(MODEL_DIR, exist_ok=True); os.makedirs(REPORT_DIR, exist_ok=True)

LABELS = ["lying", "sitting/idle", "walking", "running", "sprinting/jumping"]
AFFECT_TABLE = {
    "lying": (0.20, 0.70),
    "sitting/idle": (0.30, 0.60),
    "walking": (0.45, 0.65),
    "running": (0.70, 0.65),
    "sprinting/jumping": (0.85, 0.60),
}

# ---- æ•°æ®ç»“æ„ ----
@dataclass
class Segment:
    seg_id: str
    t_start: float
    t_end: float
    features: np.ndarray
    auto_label: str
    auto_conf: float
    bark: bool  # ç›®å‰ç¦ç”¨éŸ³é¢‘ï¼Œæ’ä¸º False

# ---- å·¥å…·å‡½æ•° ----
def iou(a, b):
    xA, yA = max(a[0], b[0]), max(a[1], b[1])
    xB, yB = min(a[2], b[2]), min(a[3], b[3])
    inter = max(0, xB - xA) * max(0, yB - yA)
    areaA = (a[2]-a[0])*(a[3]-a[1]); areaB = (b[2]-b[0])*(b[3]-b[1])
    return inter / (areaA + areaB - inter + 1e-6)

def rule_behavior(speed_px: float, aspect_ratio: float, area_change: float) -> Tuple[str, float]:
    # é€Ÿåº¦ä¸»å¯¼ + å½¢æ€ä¿®æ­£ï¼ˆè½»é‡å¯å‘å¼ï¼‰
    if speed_px < 2.0:
        if aspect_ratio < 0.85 and area_change < 0.01:
            return "lying", 0.70
        return "sitting/idle", 0.60
    elif speed_px < 10.0:
        return "walking", 0.70
    elif speed_px < 23.0:
        return "running", 0.75
    else:
        return "sprinting/jumping", 0.80

def affect_from_behavior(label: str, bark: bool) -> Tuple[float, float, float]:
    a, v = AFFECT_TABLE.get(label, (0.5, 0.5))
    conf_aff = 0.45 if label in ["lying","sitting/idle"] else 0.55
    return a, v, conf_aff

# ---- æ ·æœ¬å­˜å–ï¼ˆä¸»åŠ¨å­¦ä¹ ï¼‰----
def save_sample(features: np.ndarray, true_label: str, meta: dict):
    sid = str(uuid.uuid4())
    np.save(os.path.join(DATA_DIR, f"{sid}_x.npy"), features.astype(np.float32))
    with open(os.path.join(DATA_DIR, f"{sid}_y.json"), "w") as f:
        json.dump({"y": true_label, "meta": meta}, f)

def load_samples(limit: Optional[int] = None):
    files = [f for f in os.listdir(DATA_DIR) if f.endswith("_y.json")]
    if not files:
        return None, None
    if limit:
        files = files[:limit]
    Xs, ys = [], []
    for jf in files:
        path = os.path.join(DATA_DIR, jf)
        meta = json.load(open(path))
        y = meta["y"]
        sid = jf.replace("_y.json", "")
        x = np.load(os.path.join(DATA_DIR, f"{sid}_x.npy"))
        Xs.append(x); ys.append(LABELS.index(y))
    return np.vstack(Xs), np.array(ys, dtype=np.int64)

def fit_or_partial_update(X_train: np.ndarray, y_train: np.ndarray):
    if not SK_OK:
        return None, None, None
    scaler = StandardScaler(with_mean=True, with_std=True)
    scaler.fit(X_train)
    Xs = scaler.transform(X_train)

    base = SGDClassifier(loss="log_loss", alpha=1e-4, learning_rate="optimal", random_state=42)
    classes = np.arange(len(LABELS))
    base.partial_fit(Xs, y_train, classes=classes)

    clf = CalibratedClassifierCV(base_estimator=base, method="sigmoid", cv=3)
    clf.fit(Xs, y_train)

    ts = time.strftime("%Y%m%d_%H%M%S")
    joblib.dump(clf, os.path.join(MODEL_DIR, f"behavior_clf_{ts}.joblib"))
    joblib.dump(scaler, os.path.join(MODEL_DIR, f"scaler_{ts}.joblib"))
    joblib.dump(clf, os.path.join(MODEL_DIR, "behavior_clf_latest.joblib"))
    joblib.dump(scaler, os.path.join(MODEL_DIR, "scaler_latest.joblib"))
    return clf, scaler, ts

def predict_with_model(features_vec: np.ndarray):
    if not SK_OK:
        return None
    model_p = os.path.join(MODEL_DIR, "behavior_clf_latest.joblib")
    scaler_p = os.path.join(MODEL_DIR, "scaler_latest.joblib")
    if not (os.path.exists(model_p) and os.path.exists(scaler_p)):
        return None
    clf = joblib.load(model_p); scaler = joblib.load(scaler_p)
    Xs = scaler.transform(features_vec.reshape(1, -1))
    probs = clf.predict_proba(Xs)[0]
    idx = int(np.argmax(probs))
    return LABELS[idx], float(probs[idx])

# ---- æ¨¡å‹åŠ è½½ ----
@st.cache_resource
def load_detector():
    return YOLO("yolov8n.pt")  # é¦–æ¬¡è‡ªåŠ¨ä¸‹è½½æƒé‡

# ---- é¡µé¢ ----
st.set_page_config(page_title=APP_TITLE, layout="centered")
st.title(APP_TITLE)

# OpenCV æ£€æµ‹
if cv2 is None:
    st.error(
        "OpenCV æœªæ­£ç¡®åŠ è½½ã€‚\n\n"
        "è¯·ç¡®è®¤ `requirements.txt` ä½¿ç”¨ `opencv-python-headless==4.8.1.78`ï¼Œ"
        "å¹¶åœ¨ Streamlit Cloud çš„ **Settings â†’ Advanced â†’ Clear cache** å **Reboot**ã€‚"
    )
    if CV2_IMPORT_ERR:
        st.caption(f"å¯¼å…¥å¼‚å¸¸ï¼š{repr(CV2_IMPORT_ERR)}")
    st.stop()

# ---- ä¾§æ ï¼šç®€æ´/é«˜çº§æ¨¡å¼ ----
with st.sidebar:
    st.header("è®¾ç½®")
    pro_mode = st.toggle("é«˜çº§æ¨¡å¼ï¼ˆé¢å‘ä¸“ä¸šç”¨æˆ·ï¼‰", value=False)

    PRESETS = {
        "å®¶åº­å®¤å†…ï¼ˆæ™®é€šï¼‰":       {"conf_th": 0.35, "sample_fps": 6,  "max_seconds": 25},
        "å®¶åº­é™¢å­/æˆ·å¤–ï¼ˆå…‰çº¿è¶³ï¼‰": {"conf_th": 0.30, "sample_fps": 6,  "max_seconds": 25},
        "å¼±å…‰/æ¨¡ç³Šï¼ˆæ›´ç¨³ï¼‰":       {"conf_th": 0.45, "sample_fps": 5,  "max_seconds": 30},
        "è¿åŠ¨å¤šï¼ˆæ›´å¿«ï¼‰":         {"conf_th": 0.35, "sample_fps": 8,  "max_seconds": 20},
    }

    if not pro_mode:
        preset = st.selectbox("åœºæ™¯é¢„è®¾", list(PRESETS.keys()), index=0,
                              help="é€‰æ‹©æœ€æ¥è¿‘ä½ è§†é¢‘æ‹æ‘„ç¯å¢ƒçš„é¢„è®¾ã€‚")
        speed_vs_acc = st.slider("é€Ÿåº¦ â†” å‡†ç¡®åº¦", 0, 10, 6,
                                 help="å‘å·¦æ›´å¿«ï¼Œå‘å³æ›´å‡†ã€‚ä¸€èˆ¬ 5â€“7 å³å¯ã€‚")
        base = PRESETS[preset]
        conf_th   = float(np.clip(base["conf_th"] + (5 - speed_vs_acc) * 0.01, 0.20, 0.55))
        sample_fps = int(np.clip(base["sample_fps"] + (speed_vs_acc - 5) * 0.5, 3, 12))
        max_seconds = int(np.clip(base["max_seconds"] + (5 - speed_vs_acc) * 1.5, 10, 60))
        lowconf_th = 0.65
        st.caption(f"å½“å‰ç­–ç•¥ï¼šé˜ˆå€¼â‰ˆ{conf_th:.2f}ï¼ŒæŠ½å¸§â‰ˆ{sample_fps} fpsï¼Œæœ€é•¿åˆ†æ {max_seconds}sã€‚")
    else:
        max_seconds = st.slider("åˆ†ææ—¶é•¿ä¸Šé™(ç§’)", 5, 120, 25,
                                help="åªåˆ†æå‰ N ç§’å¯æå‡é€Ÿåº¦ã€‚")
        conf_th = st.slider("æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆYOLOï¼‰", 0.1, 0.9, 0.35,
                            help="è¶Šé«˜è¶Šå°‘è¯¯æ£€ï¼Œä½†å¯èƒ½æ¼æ£€ã€‚")
        sample_fps = st.slider("åˆ†ææŠ½å¸§é€Ÿç‡(fps)", 3, 24, 6,
                               help="åˆ†æç”¨çš„æ¯ç§’å¸§æ•°ï¼Œè¶Šé«˜è¶Šå‡†ä½†è¶Šæ…¢ã€‚")
        lowconf_th = st.slider("ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆè§¦å‘æ ‡æ³¨ï¼‰", 0.50, 0.90, 0.65,
                               help="ä½äºè¯¥å€¼çš„ç‰‡æ®µä¼šè¿›å…¥â€˜éœ€è¦äººå·¥çº æ­£â€™åŒºåŸŸã€‚")
        if SK_OK:
            st.markdown("---")
            if st.button("ğŸ§  ä½¿ç”¨å·²æ ‡æ³¨æ ·æœ¬æ”¹è¿›æ¨¡å‹"):
                X_all, y_all = load_samples()
                if X_all is None:
                    st.warning("æš‚æ— æ ‡æ³¨æ ·æœ¬ã€‚å…ˆåœ¨ä¸‹æ–¹æ—¶é—´è½´ä¸­ä¿å­˜å‡ æ¡è®­ç»ƒæ ·æœ¬ã€‚")
                else:
                    _, _, tag = fit_or_partial_update(X_all, y_all)
                    st.success(f"æ¨¡å‹å·²æ›´æ–° âœ…ï¼ˆç‰ˆæœ¬ {tag}ï¼‰")
        else:
            st.info("å¢é‡å­¦ä¹ æš‚æœªå¯ç”¨ï¼ˆsklearn æœªå®‰è£…ï¼‰ã€‚åº”ç”¨ä»å¯ç”¨ã€‚")

# ---- ä¸»åŒºï¼šä¸Šä¼ ä¸åˆ†æ ----
st.caption("ä¸Šä¼ çŸ­è§†é¢‘ï¼Œè¿›è¡Œç‹—çš„è¡Œä¸ºä¸æƒ…ç»ªï¼ˆå”¤é†’/æ•ˆä»·ï¼‰æ¨æ–­ã€‚å½“å‰ä¸º Cloud å®‰å…¨ç‰ˆï¼šéŸ³é¢‘åˆ†æ”¯å…³é—­ï¼›sklearn å®‰è£…åä¼šè‡ªåŠ¨å¯ç”¨å¢é‡å­¦ä¹ ã€‚")
uploaded = st.file_uploader("ä¸Šä¼ è§†é¢‘ (mp4/mov/mkv)", type=["mp4","mov","mkv"])

if uploaded:
    # ä¸´æ—¶ä¿å­˜
    tmpf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tmpf.write(uploaded.read()); tmpf.close()

    det = load_detector()
    cap = cv2.VideoCapture(tmpf.name)

    # è¯»å–åŸå§‹ fpsï¼Œè¿‡ä½æ—¶è‡ªåŠ¨é™ä½ sample_fps ä¸Šé™ï¼Œé¿å…å¡é¡¿
    raw_fps = cap.get(cv2.CAP_PROP_FPS) or 30
    if raw_fps < 20:
        sample_fps = min(sample_fps, 6)

    fps = raw_fps or 30
    total_frames = int(min(cap.get(cv2.CAP_PROP_FRAME_COUNT) or fps*max_seconds, max_seconds*fps))
    step = max(1, int(round(fps / sample_fps)))
    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    st.info("å¼€å§‹åˆ†æï¼ˆä¸ºæé€Ÿé‡‡ç”¨æŠ½å¸§ï¼‰ã€‚")
    progress = st.progress(0.0)

    last_box = None
    last_area = None
    segments: List[Segment] = []
    window_frames = max(3, int(sample_fps * 1.2))  # ~1.2s
    buf_feats, buf_times = [], []

    for idx in range(0, total_frames, step):
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if not ret: break
        t_sec = idx / fps

        res = det(frame, conf=conf_th, verbose=False)[0]
        dog_boxes = []
        for b in res.boxes:
            cls = int(b.cls[0].item())
            if det.model.names.get(cls, "") == "dog":
                x1,y1,x2,y2 = b.xyxy[0].cpu().numpy().astype(int).tolist()
                dog_boxes.append([x1,y1,x2,y2, float(b.conf[0].item())])

        if dog_boxes:
            dog_boxes.sort(key=lambda x: (x[2]-x[0])*(x[3]-x[1]), reverse=True)
            box = dog_boxes[0][:4]

            cx, cy = (box[0]+box[2])/2, (box[1]+box[3])/2
            w_box, h_box = box[2]-box[0], box[3]-box[1]
            area = w_box * h_box
            aspect = min(w_box, h_box) / (max(w_box, h_box)+1e-6)

            speed = 0.0; acc = 0.0; area_chg = 0.0
            if last_box is not None and iou(last_box, box) > 0.1:
                lx, ly = (last_box[0]+last_box[2])/2, (last_box[1]+last_box[3])/2
                speed = math.hypot(cx-lx, cy-ly)
                if last_area is not None and last_area > 0:
                    area_chg = abs(area - last_area) / (last_area + 1e-6)
            last_box, last_area = box, area

            if buf_feats:
                prev_speed = buf_feats[-1][0]
                acc = max(0.0, speed - prev_speed)

            features_vec = np.array([
                speed, acc, aspect, area/(W*H+1e-6), area_chg
            ], dtype=np.float32)
            buf_feats.append((speed, acc, aspect, area/(W*H+1e-6), area_chg))
            buf_times.append(t_sec)

            if len(buf_feats) >= window_frames:
                f = np.array(buf_feats[-window_frames:], dtype=np.float32)
                agg = np.concatenate([f.mean(axis=0), f.std(axis=0), f.max(axis=0)], axis=0)  # 15ç»´

                t0, t1 = buf_times[-window_frames], buf_times[-1]
                rb_label, rb_conf = rule_behavior(
                    speed_px=float(f[:,0].mean()),
                    aspect_ratio=float(f[:,2].mean()),
                    area_change=float(f[:,4].mean())
                )

                mdl_pred = predict_with_model(agg) if SK_OK else None
                if mdl_pred is not None:
                    auto_label, auto_conf = mdl_pred
                    if auto_conf < 0.55 and rb_conf > auto_conf:
                        auto_label, auto_conf = rb_label, rb_conf
                else:
                    auto_label, auto_conf = rb_label, rb_conf

                seg = Segment(
                    seg_id=str(uuid.uuid4()),
                    t_start=float(t0), t_end=float(t1),
                    features=agg, auto_label=auto_label, auto_conf=auto_conf,
                    bark=False
                )
                segments.append(seg)

        progress.progress(min(1.0, (idx+step)/max(1,total_frames)))

    cap.release()

    if not segments:
        st.error("æœªæ£€æµ‹åˆ°ç‹—ã€‚è¯·ç¡®ä¿ç”»é¢ä¸­æœ‰æ¸…æ™°çš„ç‹—å¹¶æœ‰è¶³å¤Ÿè¿åŠ¨ã€‚")
        st.stop()

    # â€”â€” æ—¶é—´è½´è¡¨ â€”â€” #
    st.subheader("åˆ†æç»“æœï¼ˆæ—¶é—´è½´ï¼‰")
    rows = []
    for s in segments:
        a,v,aff_c = affect_from_behavior(s.auto_label, s.bark)
        rows.append({
            "start(s)": round(s.t_start,2),
            "end(s)": round(s.t_end,2),
            "behavior": s.auto_label,
            "conf": round(s.auto_conf,2),
            "bark": "no",
            "arousal": round(a,2),
            "valence": round(v,2)
        })
    st.dataframe(rows, use_container_width=True)

    # â€”â€” ä½ç½®ä¿¡åº¦ç‰‡æ®µï¼šäººå·¥çº æ­£å¹¶ä¿å­˜ä¸ºæ ·æœ¬ â€”â€” #
    st.subheader("éœ€è¦äººå·¥çº æ­£çš„ç‰‡æ®µï¼ˆä½ç½®ä¿¡åº¦ï¼‰")
    n_flag = 0
    for s in segments:
        if s.auto_conf < lowconf_th:
            n_flag += 1
            with st.expander(f"{s.t_start:.2f}â€“{s.t_end:.2f}s  æ¨¡å‹ï¼š{s.auto_label}ï¼ˆ{s.auto_conf:.2f}ï¼‰"):
                idx0 = LABELS.index(s.auto_label) if s.auto_label in LABELS else 0
                choice = st.selectbox("çœŸå®è¡Œä¸ºæ ‡ç­¾", LABELS, index=idx0, key=f"sel_{s.seg_id}")
                if st.button("ä¿å­˜ä¸ºè®­ç»ƒæ ·æœ¬", key=f"save_{s.seg_id}"):
                    meta = {"t0": s.t_start, "t1": s.t_end, "bark": False}
                    save_sample(s.features, choice, meta)
                    st.success("æ ·æœ¬å·²ä¿å­˜ âœ… å·¦ä¾§ç‚¹å‡»â€œæ”¹è¿›æ¨¡å‹â€å³å¯å­¦ä¹ ã€‚")

    if n_flag == 0:
        st.caption("æ‰€æœ‰ç‰‡æ®µç½®ä¿¡åº¦éƒ½ä¸é”™ï¼Œæ— éœ€æ ‡æ³¨ã€‚")

    # â€”â€” æŠ¥å‘Šå¯¼å‡º â€”â€” #
    if st.button("ğŸ“„ å¯¼å‡ºæœ¬æ¬¡æŠ¥å‘Š(JSON)"):
        report = {
            "video": uploaded.name,
            "segments": [
                {
                    "t_start": s.t_start, "t_end": s.t_end,
                    "behavior": s.auto_label, "conf": s.auto_conf,
                    "bark": False,
                    "arousal": affect_from_behavior(s.auto_label, False)[0],
                    "valence": affect_from_behavior(s.auto_label, False)[1],
                } for s in segments
            ],
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        rid = time.strftime("%Y%m%d_%H%M%S")
        path = os.path.join(REPORT_DIR, f"report_{rid}.json")
        with open(path, "w") as f:
            json.dump(report, f, indent=2)
        st.success(f"å·²å¯¼å‡ºï¼š{path}")

st.markdown("---")
st.caption("å½“å‰ä¸º Cloud å®‰å…¨ç‰ˆï¼šOpenCV ä¸º headlessï¼ŒéŸ³é¢‘å…³é—­ï¼›å½“ `scikit-learn` å®‰è£…æˆåŠŸåï¼Œæ— éœ€æ”¹ä»£ç å³å¯å¯ç”¨å¢é‡å­¦ä¹ ã€‚")
